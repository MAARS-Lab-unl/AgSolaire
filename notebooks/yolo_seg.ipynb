{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc0727bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2\n",
    "import splitfolders\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c12df497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x384 26 seed masks, 10.9ms\n",
      "Speed: 1.0ms preprocess, 10.9ms inference, 6.4ms postprocess per image at shape (1, 3, 480, 384)\n",
      "\n",
      "0: 1024x1024 1 0, 1 1, 1 2, 1 3, 1 4, 1 5, 1 6, 1 7, 1 8, 1 9, 1 10, 1 11, 1 12, 1 13, 1 14, 1 15, 1 16, 1 17, 1 18, 1 19, 1 20, 1 21, 1 22, 1 23, 1 24, 1 25, 703.3ms\n",
      "Speed: 3.6ms preprocess, 703.3ms inference, 2.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 480x384 26 seed masks, 10.1ms\n",
      "Speed: 1.1ms preprocess, 10.1ms inference, 6.1ms postprocess per image at shape (1, 3, 480, 384)\n",
      "\n",
      "0: 1024x1024 1 0, 1 1, 1 2, 1 3, 1 4, 1 5, 1 6, 1 7, 1 8, 1 9, 1 10, 1 11, 1 12, 1 13, 1 14, 1 15, 1 16, 1 17, 1 18, 1 19, 1 20, 1 21, 1 22, 1 23, 1 24, 1 25, 722.7ms\n",
      "Speed: 3.5ms preprocess, 722.7ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 480x384 26 seed masks, 9.5ms\n",
      "Speed: 1.0ms preprocess, 9.5ms inference, 5.7ms postprocess per image at shape (1, 3, 480, 384)\n",
      "\n",
      "0: 1024x1024 1 0, 1 1, 1 2, 1 3, 1 4, 1 5, 1 6, 1 7, 1 8, 1 9, 1 10, 1 11, 1 12, 1 13, 1 14, 1 15, 1 16, 1 17, 1 18, 1 19, 1 20, 1 21, 1 22, 1 23, 1 24, 1 25, 720.4ms\n",
      "Speed: 4.2ms preprocess, 720.4ms inference, 2.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 480x384 23 seed masks, 10.0ms\n",
      "Speed: 1.2ms preprocess, 10.0ms inference, 5.5ms postprocess per image at shape (1, 3, 480, 384)\n",
      "\n",
      "0: 1024x1024 1 0, 1 1, 1 2, 1 3, 1 4, 1 5, 1 6, 1 7, 1 8, 1 9, 1 10, 1 11, 1 12, 1 13, 1 14, 1 15, 1 16, 1 17, 1 18, 1 19, 1 20, 1 21, 1 22, 703.0ms\n",
      "Speed: 3.7ms preprocess, 703.0ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 480x384 31 seed masks, 9.2ms\n",
      "Speed: 1.4ms preprocess, 9.2ms inference, 6.3ms postprocess per image at shape (1, 3, 480, 384)\n",
      "\n",
      "0: 1024x1024 1 0, 1 1, 1 2, 1 3, 1 4, 1 5, 1 6, 1 7, 1 8, 1 9, 1 10, 1 11, 1 12, 1 13, 1 14, 1 15, 1 16, 1 17, 1 18, 1 19, 1 20, 1 21, 1 22, 1 23, 1 24, 1 25, 1 26, 1 27, 1 28, 1 29, 1 30, 746.9ms\n",
      "Speed: 3.2ms preprocess, 746.9ms inference, 2.5ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 480x384 27 seed masks, 8.9ms\n",
      "Speed: 1.0ms preprocess, 8.9ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 384)\n",
      "\n",
      "0: 1024x1024 1 0, 1 1, 1 2, 1 3, 1 4, 1 5, 1 6, 1 7, 1 8, 1 9, 1 10, 1 11, 1 12, 1 13, 1 14, 1 15, 1 16, 1 17, 1 18, 1 19, 1 20, 1 21, 1 22, 1 23, 1 24, 1 25, 1 26, 726.1ms\n",
      "Speed: 3.6ms preprocess, 726.1ms inference, 2.1ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 480x384 23 seed masks, 9.2ms\n",
      "Speed: 1.3ms preprocess, 9.2ms inference, 5.4ms postprocess per image at shape (1, 3, 480, 384)\n",
      "\n",
      "0: 1024x1024 1 0, 1 1, 1 2, 1 3, 1 4, 1 5, 1 6, 1 7, 1 8, 1 9, 1 10, 1 11, 1 12, 1 13, 1 14, 1 15, 1 16, 1 17, 1 18, 1 19, 1 20, 1 21, 1 22, 700.2ms\n",
      "Speed: 3.4ms preprocess, 700.2ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 480x384 26 seed masks, 9.7ms\n",
      "Speed: 1.2ms preprocess, 9.7ms inference, 5.4ms postprocess per image at shape (1, 3, 480, 384)\n",
      "\n",
      "0: 1024x1024 1 0, 1 1, 1 2, 1 3, 1 4, 1 5, 1 6, 1 7, 1 8, 1 9, 1 10, 1 11, 1 12, 1 13, 1 14, 1 15, 1 16, 1 17, 1 18, 1 19, 1 20, 1 21, 1 22, 1 23, 1 24, 1 25, 720.4ms\n",
      "Speed: 3.6ms preprocess, 720.4ms inference, 2.1ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 480x384 26 seed masks, 9.3ms\n",
      "Speed: 1.4ms preprocess, 9.3ms inference, 5.9ms postprocess per image at shape (1, 3, 480, 384)\n",
      "\n",
      "0: 1024x1024 1 0, 1 1, 1 2, 1 3, 1 4, 1 5, 1 6, 1 7, 1 8, 1 9, 1 10, 1 11, 1 12, 1 13, 1 14, 1 15, 1 16, 1 17, 1 18, 1 19, 1 20, 1 21, 1 22, 1 23, 1 24, 1 25, 720.6ms\n",
      "Speed: 3.3ms preprocess, 720.6ms inference, 2.1ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 480x384 24 seed masks, 8.9ms\n",
      "Speed: 1.8ms preprocess, 8.9ms inference, 5.6ms postprocess per image at shape (1, 3, 480, 384)\n",
      "\n",
      "0: 1024x1024 1 0, 1 1, 1 2, 1 3, 1 4, 1 5, 1 6, 1 7, 1 8, 1 9, 1 10, 1 11, 1 12, 1 13, 1 14, 1 15, 1 16, 1 17, 1 18, 1 19, 1 20, 1 21, 1 22, 1 23, 707.7ms\n",
      "Speed: 4.0ms preprocess, 707.7ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 480x384 30 seed masks, 8.9ms\n",
      "Speed: 1.2ms preprocess, 8.9ms inference, 6.9ms postprocess per image at shape (1, 3, 480, 384)\n",
      "\n",
      "0: 1024x1024 1 0, 1 1, 1 2, 1 3, 1 4, 1 5, 1 6, 1 7, 1 8, 1 9, 1 10, 1 11, 1 12, 1 13, 1 14, 1 15, 1 16, 1 17, 1 18, 1 19, 1 20, 1 21, 1 22, 1 23, 1 24, 1 25, 1 26, 1 27, 1 28, 1 29, 739.3ms\n",
      "Speed: 3.6ms preprocess, 739.3ms inference, 2.4ms postprocess per image at shape (1, 3, 1024, 1024)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO, SAM\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# ===== CONFIG =====\n",
    "model = YOLO(\"runs/segment/Newagsolaire_yolo_segmentation/weights/best.pt\")\n",
    "images_folder = \"/home/sowmya/AgSolaire/train_val_test_split/test/images\"\n",
    "sam_model = SAM(\"sam2_b.pt\")\n",
    "\n",
    "PX_PER_MM = None   # e.g. 12.5 if you know calibration; else stays in px\n",
    "\n",
    "# ===== MAIN LOOP =====\n",
    "for file in os.listdir(images_folder):\n",
    "    full_path = os.path.join(images_folder, file)\n",
    "    if not os.path.isfile(full_path):\n",
    "        continue\n",
    "\n",
    "    image = cv2.imread(full_path)\n",
    "    image = cv2.resize(image, (680, 900))\n",
    "\n",
    "    # Run YOLO detection\n",
    "    results = model.predict(source=image, conf=0.8)\n",
    "    boxes = results[0].boxes.xyxy.cpu().numpy()\n",
    "\n",
    "    # Run SAM segmentation using YOLO boxes as prompts\n",
    "    sam_results = sam_model(image, bboxes=boxes)\n",
    "\n",
    "    overlay = image.copy()\n",
    "    seed_id = 0\n",
    "\n",
    "    for r in sam_results:\n",
    "        masks = r.masks.data.cpu().numpy()  # [N, H, W]\n",
    "\n",
    "        for mask in masks:\n",
    "            seed_id += 1\n",
    "            mask = (mask > 0.5).astype(np.uint8)  # ensure binary mask\n",
    "\n",
    "            # Find contour\n",
    "            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            if not contours:\n",
    "                continue\n",
    "\n",
    "            cnt = max(contours, key=cv2.contourArea)\n",
    "\n",
    "            # Fit rotated rectangle\n",
    "            rect = cv2.minAreaRect(cnt)     # (center, (w,h), angle)\n",
    "            (cx, cy), (w, h), angle = rect\n",
    "            length_px = max(w, h)\n",
    "            width_px  = min(w, h)\n",
    "\n",
    "            # Convert to mm if calibration is known\n",
    "            length_mm = length_px / PX_PER_MM if PX_PER_MM else None\n",
    "            width_mm  = width_px  / PX_PER_MM if PX_PER_MM else None\n",
    "\n",
    "            # Draw rectangle\n",
    "            box = cv2.boxPoints(rect)\n",
    "            box = np.int32(box)\n",
    "            cv2.polylines(overlay, [box], True, (255, 0, 0), 2)\n",
    "\n",
    "            # Draw center point\n",
    "            cv2.circle(overlay, (int(cx), int(cy)), 4, (0, 255, 0), -1)\n",
    "\n",
    "            # Put text label (both length and width)\n",
    "            if length_mm and width_mm:\n",
    "                label = f\"{seed_id}: {length_mm:.2f} x {width_mm:.2f} mm\"\n",
    "            else:\n",
    "                label = f\"{seed_id}: {length_px:.1f} x {width_px:.1f} px\"\n",
    "\n",
    "            cv2.putText(overlay, label, (int(cx)+10, int(cy)-10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "\n",
    "    # Blend overlay with original image\n",
    "    out = cv2.addWeighted(image, 0.7, overlay, 0.3, 0)\n",
    "\n",
    "    cv2.imshow(\"Seeds with Lengths & Widths\", out)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38fba133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 512x640 33 seed masks, 46.7ms\n",
      "Speed: 1.7ms preprocess, 46.7ms inference, 8.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 1024x1024 1 0, 1 1, 1 2, 1 3, 1 4, 1 5, 1 6, 1 7, 1 8, 1 9, 1 10, 1 11, 1 12, 1 13, 1 14, 1 15, 1 16, 1 17, 1 18, 1 19, 1 20, 1 21, 1 22, 1 23, 1 24, 1 25, 1 26, 1 27, 1 28, 1 29, 1 30, 1 31, 1 32, 750.2ms\n",
      "Speed: 4.6ms preprocess, 750.2ms inference, 5.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 512x640 31 seed masks, 43.2ms\n",
      "Speed: 1.7ms preprocess, 43.2ms inference, 7.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 1024x1024 1 0, 1 1, 1 2, 1 3, 1 4, 1 5, 1 6, 1 7, 1 8, 1 9, 1 10, 1 11, 1 12, 1 13, 1 14, 1 15, 1 16, 1 17, 1 18, 1 19, 1 20, 1 21, 1 22, 1 23, 1 24, 1 25, 1 26, 1 27, 1 28, 1 29, 1 30, 751.0ms\n",
      "Speed: 4.4ms preprocess, 751.0ms inference, 5.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 512x640 24 seed masks, 38.1ms\n",
      "Speed: 1.9ms preprocess, 38.1ms inference, 6.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 1024x1024 1 0, 1 1, 1 2, 1 3, 1 4, 1 5, 1 6, 1 7, 1 8, 1 9, 1 10, 1 11, 1 12, 1 13, 1 14, 1 15, 1 16, 1 17, 1 18, 1 19, 1 20, 1 21, 1 22, 1 23, 708.5ms\n",
      "Speed: 4.3ms preprocess, 708.5ms inference, 4.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 512x640 28 seed masks, 38.5ms\n",
      "Speed: 1.9ms preprocess, 38.5ms inference, 7.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 1024x1024 1 0, 1 1, 1 2, 1 3, 1 4, 1 5, 1 6, 1 7, 1 8, 1 9, 1 10, 1 11, 1 12, 1 13, 1 14, 1 15, 1 16, 1 17, 1 18, 1 19, 1 20, 1 21, 1 22, 1 23, 1 24, 1 25, 1 26, 1 27, 737.5ms\n",
      "Speed: 3.9ms preprocess, 737.5ms inference, 4.8ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 512x640 30 seed masks, 38.5ms\n",
      "Speed: 1.7ms preprocess, 38.5ms inference, 8.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 1024x1024 1 0, 1 1, 1 2, 1 3, 1 4, 1 5, 1 6, 1 7, 1 8, 1 9, 1 10, 1 11, 1 12, 1 13, 1 14, 1 15, 1 16, 1 17, 1 18, 1 19, 1 20, 1 21, 1 22, 1 23, 1 24, 1 25, 1 26, 1 27, 1 28, 1 29, 746.0ms\n",
      "Speed: 3.6ms preprocess, 746.0ms inference, 5.1ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 512x640 26 seed masks, 38.4ms\n",
      "Speed: 1.8ms preprocess, 38.4ms inference, 6.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 1024x1024 1 0, 1 1, 1 2, 1 3, 1 4, 1 5, 1 6, 1 7, 1 8, 1 9, 1 10, 1 11, 1 12, 1 13, 1 14, 1 15, 1 16, 1 17, 1 18, 1 19, 1 20, 1 21, 1 22, 1 23, 1 24, 1 25, 724.8ms\n",
      "Speed: 3.5ms preprocess, 724.8ms inference, 4.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 512x640 24 seed masks, 38.6ms\n",
      "Speed: 1.8ms preprocess, 38.6ms inference, 6.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 1024x1024 1 0, 1 1, 1 2, 1 3, 1 4, 1 5, 1 6, 1 7, 1 8, 1 9, 1 10, 1 11, 1 12, 1 13, 1 14, 1 15, 1 16, 1 17, 1 18, 1 19, 1 20, 1 21, 1 22, 1 23, 709.9ms\n",
      "Speed: 4.1ms preprocess, 709.9ms inference, 4.2ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 512x640 23 seed masks, 38.1ms\n",
      "Speed: 1.8ms preprocess, 38.1ms inference, 6.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 1024x1024 1 0, 1 1, 1 2, 1 3, 1 4, 1 5, 1 6, 1 7, 1 8, 1 9, 1 10, 1 11, 1 12, 1 13, 1 14, 1 15, 1 16, 1 17, 1 18, 1 19, 1 20, 1 21, 1 22, 705.1ms\n",
      "Speed: 3.7ms preprocess, 705.1ms inference, 4.2ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 512x640 30 seed masks, 38.3ms\n",
      "Speed: 2.1ms preprocess, 38.3ms inference, 8.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 1024x1024 1 0, 1 1, 1 2, 1 3, 1 4, 1 5, 1 6, 1 7, 1 8, 1 9, 1 10, 1 11, 1 12, 1 13, 1 14, 1 15, 1 16, 1 17, 1 18, 1 19, 1 20, 1 21, 1 22, 1 23, 1 24, 1 25, 1 26, 1 27, 1 28, 1 29, 746.1ms\n",
      "Speed: 3.4ms preprocess, 746.1ms inference, 5.1ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 512x640 26 seed masks, 38.9ms\n",
      "Speed: 1.8ms preprocess, 38.9ms inference, 6.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 1024x1024 1 0, 1 1, 1 2, 1 3, 1 4, 1 5, 1 6, 1 7, 1 8, 1 9, 1 10, 1 11, 1 12, 1 13, 1 14, 1 15, 1 16, 1 17, 1 18, 1 19, 1 20, 1 21, 1 22, 1 23, 1 24, 1 25, 726.5ms\n",
      "Speed: 4.1ms preprocess, 726.5ms inference, 4.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 512x640 27 seed masks, 38.6ms\n",
      "Speed: 2.1ms preprocess, 38.6ms inference, 6.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 1024x1024 1 0, 1 1, 1 2, 1 3, 1 4, 1 5, 1 6, 1 7, 1 8, 1 9, 1 10, 1 11, 1 12, 1 13, 1 14, 1 15, 1 16, 1 17, 1 18, 1 19, 1 20, 1 21, 1 22, 1 23, 1 24, 1 25, 1 26, 729.5ms\n",
      "Speed: 4.6ms preprocess, 729.5ms inference, 5.0ms postprocess per image at shape (1, 3, 1024, 1024)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO, SAM\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# ===== CONFIG =====\n",
    "model = YOLO(\"/home/sowmya/Downloads/best.pt\")\n",
    "images_folder = \"/home/sowmya/AgSolaire/train_val_test_split/test/images\"\n",
    "sam_model = SAM(\"sam2_b.pt\")\n",
    "\n",
    "PX_PER_MM = None   # e.g. 12.5 if you know calibration; else stays in px\n",
    "\n",
    "# ===== MAIN LOOP =====\n",
    "for file in os.listdir(images_folder):\n",
    "    full_path = os.path.join(images_folder, file)\n",
    "    if not os.path.isfile(full_path):\n",
    "        continue\n",
    "\n",
    "    image = cv2.imread(full_path)\n",
    "    image = cv2.resize(image, (1400, 1120))\n",
    "\n",
    "    # Run YOLO detection\n",
    "    results = model.predict(source=image, conf=0.7)\n",
    "    boxes = results[0].boxes.xyxy.cpu().numpy()\n",
    "\n",
    "    # Run SAM segmentation using YOLO boxes as prompts\n",
    "    sam_results = sam_model(image, bboxes=boxes)\n",
    "\n",
    "    overlay = image.copy()\n",
    "    seed_id = 0\n",
    "\n",
    "    for r in sam_results:\n",
    "        masks = r.masks.data.cpu().numpy()  # [N, H, W]\n",
    "\n",
    "        for mask in masks:\n",
    "            seed_id += 1\n",
    "            mask = (mask > 0.5).astype(np.uint8)  # ensure binary mask\n",
    "\n",
    "            # Find contour\n",
    "            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            if not contours:\n",
    "                continue\n",
    "\n",
    "            cnt = max(contours, key=cv2.contourArea)\n",
    "\n",
    "            # ---- Fit ellipse instead of rectangle ----\n",
    "            if len(cnt) < 5:   # cv2.fitEllipse requires >=5 points\n",
    "                continue\n",
    "\n",
    "            ellipse = cv2.fitEllipse(cnt)   # (center(x,y), (major_axis, minor_axis), angle)\n",
    "            (cx, cy), (MA, ma), angle = ellipse\n",
    "\n",
    "            # Major = length, Minor = width\n",
    "            length_px = max(MA, ma)\n",
    "            width_px  = min(MA, ma)\n",
    "\n",
    "            # Convert to mm if calibration known\n",
    "            length_mm = length_px / PX_PER_MM if PX_PER_MM else None\n",
    "            width_mm  = width_px  / PX_PER_MM if PX_PER_MM else None\n",
    "\n",
    "            # ---- Draw ellipse ----\n",
    "            cv2.ellipse(overlay, ellipse, (0, 255, 0), 2)  # blue ellipse\n",
    "            cv2.circle(overlay, (int(cx), int(cy)), 4, (0, 255, 0), -1)  # green center\n",
    "\n",
    "            # Put text label\n",
    "            if length_mm and width_mm:\n",
    "                label = f\"{seed_id}: {length_mm:.2f} x {width_mm:.2f} mm\"\n",
    "            else:\n",
    "                label = f\"{seed_id}: {length_px:.1f} x {width_px:.1f} px\"\n",
    "\n",
    "            # cv2.putText(overlay, label, (int(cx)+10, int(cy)-10),\n",
    "                        # cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "\n",
    "    # Blend overlay with original image\n",
    "    out = cv2.addWeighted(image, 0.7, overlay, 0.3, 0)\n",
    "\n",
    "    cv2.imshow(\"Seeds with Lengths & Widths (Ellipses)\", out)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6e1bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agsolaire_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
